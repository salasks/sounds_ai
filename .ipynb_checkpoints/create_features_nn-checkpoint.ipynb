{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        fp ='data/fold1/'+ fp\n",
    "        X,sr = librosa.load(fp)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "sound_names = [\"air conditioner\",\"car horn\",\"children playing\",\n",
    "\"dog bark\",\"drilling\",\"engine idling\", \"gun shot\",\n",
    "\"jackhammer\",\"siren\",\"street music\"]\n",
    "# sound_file_paths = ['7061-6-0-0.wav']\n",
    "# raw_sounds2 = load_sound_files(sound_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=MhOdbtPhbLU\n",
    "# see if I can get one of these for conv layers\n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    # spectogram\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "  \n",
    "    \n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext=\"*.wav\"):\n",
    "    features, labels = np.empty((0,193)), np.empty(0)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        print('ha')\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            try:\n",
    "              mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "            except Exception as e:\n",
    "              print( \"Error encountered while parsing file: \", fn)\n",
    "              continue\n",
    "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "            features = np.vstack([features,ext_features])\n",
    "            labels = np.append(labels, fn.split('/')[2].split('-')[1])\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha\n",
      "ha\n"
     ]
    }
   ],
   "source": [
    "parent_dir = 'data'\n",
    "tr_sub_dirs = [\"fold8\",\"fold9\"]\n",
    "# ts_sub_dirs = [\"fold1\"]\n",
    "tr_features_get, tr_labels_get = parse_audio_files(parent_dir,tr_sub_dirs)\n",
    "# ts_features, ts_labels = parse_audio_files(parent_dir,ts_sub_dirs)\n",
    "\n",
    "tr_labels_get = one_hot_encode(tr_labels_get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tr_features = np.load('tr_features.npy')\n",
    "tr_labels = np.load('tr_labels.npy')\n",
    "# print(tr_features.shape,tr_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_features = np.append(tr_features, tr_features_get, axis=0)\n",
    "tr_labels = np.append(tr_labels, tr_labels_get, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('tr_features.npy', tr_features, allow_pickle=True)\n",
    "np.save('tr_labels.npy', tr_labels, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_features = np.load('tr_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8596, 193)\n",
      "(8596, 10)\n"
     ]
    }
   ],
   "source": [
    "print(tr_features.shape)\n",
    "print(tr_labels.shape)\n",
    "# go back to wave \n",
    "# https://stackoverflow.com/questions/34710011/how-do-i-go-from-sound-to-spectrum-then-back-to-sound-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "# load a remote WAV file\n",
    "\n",
    "fs = 44100 # sampling frequency\n",
    "T = 1.5    # seconds\n",
    "t = np.linspace(0, T, int(T*fs), endpoint=False) # time variable\n",
    "x = np.sin(2*np.pi*440*t)                # pure sine wave at 440 Hz\n",
    "\n",
    "# load a NumPy array\n",
    "Audio(x, rate=fs)\n",
    "# Audio('https://ccrma.stanford.edu/workshops/mir2014/audio/CongaGroove-mono.wav')\n",
    "x, fs = librosa.load('data/my_data/barking-3-0-0.wav')\n",
    "Audio(x, rate=fs)\n",
    "melspec2 = librosa.feature.melspectrogram(x, n_mels = 60, sr=fs)\n",
    "logspec2 = librosa.logamplitude(melspec2,)\n",
    "librosa.display.specshow(logspec2, y_axis='log')\n",
    "\n",
    "print(logspec2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "librosa.display.specshow(logspec2[:,80:], y_axis='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_aws.upload_data import upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/fold10\n"
     ]
    }
   ],
   "source": [
    "upload(['fold4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
